{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "import csv\n",
    "import os\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_section(f):\n",
    "    sents_list=[]\n",
    "    section={}\n",
    "    for para in f:\n",
    "        p=sent_tokenize(para)\n",
    "        for sent in p:\n",
    "            if sent != []:\n",
    "                if  len(sent)<30:\n",
    "                     section[len(sents_list)]=sent\n",
    "                else:\n",
    "                     sents_list.append(sent)\n",
    "   \n",
    "\n",
    "    return(section, sents_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords={1:[\"eligibility\", \"inclusion\", \"exclusion\", \"criteria\"],\n",
    "2:[\"random\", \"alternate\", \"allocate\"],\n",
    "3:[\"allocation\", \"concealed\",\"concealment\"],\n",
    "4:[\"baseline\", \"characteristic\", \"age\", \"sex\", \"gender\", \"demographic\"],\n",
    "5:[\"mask\",\"masking\",\"blinding\",\"blind\"],\n",
    "6:[\"mask\",\"masking\",\"blinding\",\"blind\"],\n",
    "7:[\"mask\",\"masking\",\"blinding\",\"blind\"],\n",
    "8:[\"dropout\",  \"attrition\", \"withdraw\", \"withdrew\", \"complete(d)\",\"complete\"],\n",
    "9:[\"intention-to-treat\", \"intention\"],\n",
    "10:[\"inter-group\", \"between-group\", \"anova\", \"t-test\", \"analysis\",\"variance\"],\n",
    "11:[\"mean\", \"standard\", \"deviation\", \"sd\", \"error\", \"sem\", \"se\", \"variance\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "headers=[\"PubMedID\",\"#sentences\",\"#Q1(K1/K2)\",\"#Q2(K1/K2)\",\"#Q3(K1/K2)\",\"#Q4(K1/K2)\",\n",
    "         \"#Q5(K1/K2)\",\"#Q8(K1/K2)\",\"#Q9(K1/K2)\",\"#Q10(K1/K2)\",\"#Q11(K1/K2)\"]\n",
    "head=[\"Sentence-ID\",\"Sentence-String\",\"Q1\",\"Q2\",\"Q3\",\"Q4\",\"Q5\",\"Q6\",\"Q7\",\"Q8\",\"Q9\", \"Q10\",\"Q11\",\"Section\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist=[]\n",
    "for filename in os.listdir('/Users/veronica/Documents/research/pmarticle'):\n",
    "    filelist.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('a_statistic.csv','w',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    csv.writer(f).writerow(headers)\n",
    "    for name in filelist[2:-2]:\n",
    "        csvrow=[name]\n",
    "        f=open(name,'r')\n",
    "        section, sents=sentence_section(f)\n",
    "        length=len(sents)\n",
    "        csvrow.append(length)\n",
    "        for i in {1,2,3,4,5,8,9,10,11}:\n",
    "            one,two=find_keywords(sents,length,keywords[i])\n",
    "            csvrow.append(str(one)+'/'+str(two))\n",
    "        writer.writerow(csvrow)\n",
    "        f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in filelist[2:-2]:\n",
    "    with open('/Users/veronica/Documents/research/sentences/{}.csv'.format(file),'w',newline='') as f:\n",
    "        writer=csv.writer(f)\n",
    "        writer.writerow(head)\n",
    "        f1=open(file,'r')\n",
    "        section, sents=sentence_section(f1)\n",
    "        f1.close()\n",
    "        for i in range(len(sents)):\n",
    "            csvrow=[i,sents[i]]\n",
    "            word_list=word_tokenize(sents[i].lower())\n",
    "            for j in keywords.keys():\n",
    "                flag=0\n",
    "                for key in keywords[j]:\n",
    "                    if key in word_list:\n",
    "                        flag=1\n",
    "                csvrow.append(flag)\n",
    "            if i in section.keys():\n",
    "                csvrow.append(section[i])\n",
    "        \n",
    "            writer.writerow(csvrow) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"/Users/veronica/Documents/research/data.csv\", \"r\", encoding = 'unicode_escape') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    rows= [row for row in reader]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rows[0])):\n",
    "    if rows[0][i]=='articleId':\n",
    "        print(i)\n",
    "for i in range(len(rows[0])):\n",
    "    if rows[0][i]=='Q1 Comment':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"/Users/veronica/Documents/research/data.csv\", \"r\", encoding = 'unicode_escape') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    rows= [row for row in reader]\n",
    "    \n",
    "head1=[\"Sentence-ID\",\"Sentence-String\",\"Q1\",\"Q2\",\"Q3\",\"Q4\",\"Q5\",\"Q6\",\"Q7\",\"Q8\",\"Q9\", \"Q10\",\"Q11\"]\n",
    "question=['Q1','Q2','Q3','Q4','Q5','Q6','Q7','Q8','Q9','Q10','Q11']\n",
    "for file in filelist[2:-2]:\n",
    "    with open('/Users/veronica/Documents/research/standard/{}.csv'.format(file),'w',newline='') as f:\n",
    "        writer=csv.writer(f)\n",
    "        writer.writerow(head1)\n",
    "        f1=open(file,'r')\n",
    "        section, sents=sentence_section(f1)\n",
    "        f1.close()\n",
    "        \n",
    "        row=[]\n",
    "        for i in range(len(rows)):\n",
    "            if rows[i][14]==file:\n",
    "                row.append(i)\n",
    "        for i in range(11):\n",
    "            question[i]=[]\n",
    "            for j in row:\n",
    "                question[i].append(rows[j][i*2+23])\n",
    "                \n",
    "\n",
    "        sec=''\n",
    "        for i in range(len(sents)):\n",
    "            csvrow=[i,sents[i]]\n",
    "            \n",
    "            if i in section.keys():\n",
    "                sec=section[i]\n",
    "            for j in range(11):\n",
    "                flag=0\n",
    "                if question[j]==['']:\n",
    "                    csvrow.append(\"N\")\n",
    "                else:\n",
    "                    for com in question[j]:\n",
    "                        if len(com)<30:\n",
    "                            if difflib.SequenceMatcher(None, com, sec).ratio()>0.5:\n",
    "                                flag=1\n",
    "                        else:\n",
    "                            if difflib.SequenceMatcher(None, com, sents[i]).ratio()>0.5:\n",
    "                                flag=1 \n",
    "                \n",
    "                    csvrow.append(flag)            \n",
    "            writer.writerow(csvrow)            \n",
    "            \n",
    "                    \n",
    "                \n",
    "        \n",
    "            \n",
    "            \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "print(difflib.SequenceMatcher(None, \"abc\", \"abc\").ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.053357395804957776, 0.04434743443162526, 0.04343850022862369, 0.1107666717072433, 0.036284777319369514, 0.034897405720718415, 0.03563990912533131, 0.055169235924932974, 0.04381443298969072, 0.08674417757043408, 0.10606653620352251]\n"
     ]
    }
   ],
   "source": [
    "path1 = \"/Users/veronica/Documents/research/sentences\"\n",
    "path2 = \"/Users/veronica/Documents/research/standard\"\n",
    "count=[0,0,0,0,0,0,0,0,0,0,0]\n",
    "total=[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
    "filename=[]\n",
    "for file in os.listdir(path1)[3:]:\n",
    "    with open(os.path.join(path1, file), 'r',encoding = 'unicode_escape') as f1:\n",
    "        reader1 = csv.reader(f1)\n",
    "        rows1= [row for row in reader1]\n",
    "    with open(os.path.join(path2, file), 'r',encoding = 'unicode_escape') as f2:\n",
    "        reader2 = csv.reader(f2)\n",
    "        rows2= [row for row in reader2]\n",
    "    N=len(rows1)\n",
    "    for i in range(2,13):\n",
    "        if rows2[2][i]!='N':\n",
    "            total[i-2]+=N\n",
    "            for j in range(1,N):\n",
    "                if rows2[j][i]!=rows1[j][i]:\n",
    "                    count[i-2]+=1\n",
    "                \n",
    "proportion=[]     #mistake            \n",
    "for i in range(11):\n",
    "    proportion.append(count[i]/total[i])\n",
    "print(proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
